
Course: Apache Kafka for Event-Driven Spring Boot Microservices

Start: 28/11/2025


****************************************
Section 1: Introduction to Apache Kafka
****************************************

- What is a Microservice?
    - Small autonomous application, that is usually designed to perform a one specific
      business functionality.
    - Responsible for specific functionality (Search, Email Notification, SMS Notification).
    - Loosely coupled, designed to scale and work in the cloud.

- Communication between Microservices.
    - It is performed by HTTP Requests in sync or async mode.

- Event-Driven Architecture: to send a message to differente applications at the same time.




********************************
Section 2: Apache Kafka Brokers
********************************


- Start single Apache Kafka broker with KRaft

    - docs: https://www.confluent.io/blog/set-up-and-run-kafka-on-windows-linux-wsl-2/

    - Clean up:
        
        rm -rf /tmp/kafka-logs /tmp/zookeeper /tmp/kraft-combined-logs

    - KAFKA_CLUSTER_ID="$(bin/kafka-storage.sh random-uuid)"
    - echo $KAFKA_CLUSTER_ID
    - bin/kafka-storage.sh format -t $KAFKA_CLUSTER_ID -c config/kraft/server.properties
    - bin/kafka-server-start.sh config/kraft/server.properties


* Don't use this configuration to avoid issues.

- Multiple Kafka broker: Configuration Files (Multiple servers in a single cluster)
    - /config/kraft/
    - make copies of server.properties (server-1.properties, server-2.properties)
    - On server-2.properties
        - node.id=2
        - listeners=PLAINTEXT://:9094,CONTROLLER://:9095 
        - controller.quorum.voters=1@localhost:9093,2@localhost:9095  (do the same in server-1, the same entire value)
        - advertised.listeners=PLAINTEXT://localhost:9094
        - log.dirs=/tmp/server-2/kraft-combined-logs (do similar to server-1)

- Multiple Kafka broker: Storage folders
    - bin/kafka-storage.sh random-uuid
    - bin/kafka-storage.sh format -t dw6Kk_63Qrab_bN87YRAvg -c config/kraft/server-1.properties
    - bin/kafka-storage.sh format -t dw6Kk_63Qrab_bN87YRAvg -c config/kraft/server-2.properties   ---> is the same key as server-1


- Starting multiple Kafka broker with KRaft
    - bin/kafka-server-start.sh config/kraft/server-1.properties
    - bin/kafka-server-start.sh config/kraft/server-2.properties
    - see the logs, no errors, and the reference of the nodes.

- Stop Producers and Consumers
    - avoid losing messages and errors.
    - bin/kafka-server-stop.sh ---> graceful shutdown, better then control+c (2 servers down automatically)

-------------------------------------


*****************************
Section 3: Kafka CLI: Topics
*****************************

    - start both brokers in the cluster.

    - bin/kafka-topics.sh --bootstrap-server localhost:9092 --list

    - bin/kafka-topics.sh --bootstrap-server localhost:9092,localhost:9094 --create --topic topic1 --partitions 3 --replication-factor 2

        - Number of partitions should be the same of number of consumers.
        - replication factor: how many copies of each partition are store across of different servers. fault tolerance.
          data available even if a broker fails. this number cannot be greater than the number of brokers in the cluster.
    
    - bin/kafka-topics.sh --bootstrap-server localhost:9092,localhost:9094 --create --topic topic2 --partitions 3 --replication-factor 2

    - bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe

    - bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic topic1



********************************
Section 4: Kafka CLI: Producers
********************************

    - Send a message with or without a Key.
    - Send multiple messages from a file.

    - Use only one server

    - Without a key

        - bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic topic3

            - if the topic doesn't exist it will be created automatically
        
    - Key:Value Pair

        - bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic topic4 --property "parse.key=true" --property "key.separator=:"

            - firstName:Julio
            - other format throws an error



********************************
Section 5: Kafka CLI: Consumers
********************************

    - bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic my-topic --from-beginning
    - the message still alive in the topic after it was read
    - one or more consumers can see the messages from the topic

    - Consuming new messages only
        - enter the command without the --from-beginning option
    
    - Consuming Key:Value pair messages from Kafka topic
        
        - bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic my-topic --property "parse.key=true" --property "key.separator=:"

        - I need to add the print.key property, otherwise I just received the value

            - bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic my-topic --from-beginning --property print.key=true

        - I also can print the value or not

            - bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic my-topic --from-beginning --property print.key=true --property print.value=false

    - Consuming Kafka messages in order

        Messages with the same key are ordered in the same partition but the others are distributed across different partitions and there is no guarantee of order.

        - bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic messages-order --partitions 3 --replication-factor 2

        - bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic messages-order --property "parse.key=true" --property "key.separator=:"

            >1:message1
            >1:message2
            >1:message3
            >1:message4
            >1:message5
            >a:a
            >b:b
            >c:c
            >d:d
            >e:e
            >f:f
            >g:g

        - bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic messages-order --from-beginning --property print.key=true --property print.value=true

            a       a
            c       c
            b       b
            d       d
            e       e
            1       message1
            1       message2
            1       message3
            1       message4
            1       message5
            f       f
            g       g            


****************************************************
Section 5: Kafka Producer - Spring Boot Microservice
****************************************************

branch: feature/section5-kafka-producer-microservice

    - Create new project
        - com.vilelo.ws
        - products-microservice
        - package: products
        - java 17
        - dependency: web, spring for kafka

    - add jackson dependency

    - configs on properties
        - server.port=0  ---> takes a random port
        - the correct key is just kafka server not producer server. 

    - create KafkaConfig, I don't use the replicas because I only have 1 server

    - for the wsl use: ip addr show
        - use the eth0

    - edit server.properties with this:
        listeners=PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
        advertised.listeners=PLAINTEXT://172.30.84.55:9092

    - terminate the code (controller, service, config, model)
        - use join() if you want to wait confirmation from kafka

    - use a consumer:
        - bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic product-created-events-topic --property print.key=true --property print.value=true

    - test successful
        - kafka console: fbfd8ab3-55e4-4c91-98cd-df0eda942a87    {"productId":"fbfd8ab3-55e4-4c91-98cd-df0eda942a87","title":"iPhone 13","price":1700,"quantity":1}
        - even the logs are correct (async communication):
            - first : *********** Returning product id   (at the final of the method)
            - and then: *********** Message sent successfully